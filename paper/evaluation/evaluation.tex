\chapter{Evaluation}\label{ch:evaluation}

Due to there being three major stages to the evaluation (preprocessing, training/testing, translating) as explained in section 4, and these three stages having different bottlenecks, not all experiments were run on the same computers. Both the preprocessing and translating stages require the reading of the entire dataset file, making it very RAM intensive. They also only require CPU work, shifting the bottleneck to the CPU after reading the file. Preprocessing also allows for CPU parallelization, making more CPUs a very good thing to have. As such the first and third stages are run on a computer with 1.5TB of ram and 16 Intel Xeon E5--2630v3 CPUs running at 2.40GHz with 32 threads.The training/testing stage however, is a very GPU intensive task. Due to parallelization being highly effective for this task, as explained in section 4, the amount of GPUs is very influential for this task, offering close to linear performance improvements, the second task was ran on a computer with 1TB of ram, 20 Intel Xeon E5--2650v3 CPUs running at 2.30GHz with 40 threads and 16 NVIDIA Tesla K80 GPUs each with 11.5GB of memory. 

Due to the size of the dataset and the limited amount of time, the decision was made to use only 5\% of the dataset for plots/results, as such the percentage that has been used will be 5\% in the following results unless states otherwise. Keep in mind that this means the first 5\% of the file, not 5\% of users. This means that approximately 3 days of data is being used. This causes many users to not have enough actions to pass the 150 actions baseline. Increasing this percentage will not only increase the actions for existing users (causing an exponential increase in work required) but also introduces new users, also leading to an exponential increase in work. 

In order to get an idea of how the percentage of the dataset takes with the time commands take to run, a percentage of 0.1\% has occasionally also been used. Doing preprocessing took 38 seconds for 0.1\% of the data while it took 1h31m for 5\% of the data, both using 10 CPUs. A very rough estimate puts the duration of preprocessing the entire dataset at about 130 hours also at 10 CPUs. Doing the training/testing stage took 1h51m using 16 GPUs using 0.1\% of the dataset, while it took %TODO: fill in
for 5\% of the data,
%TODO: Maybe remove
while 1\% took XXX, putting the total estimated time at XXX.\@ The anomaly translation part generally only takes roughly 2h30m, where the biggest time sink is loading the dataset file itself. Putting this all together, the entire process takes %TODO: fill in
for 5\% of the data. Taking 5\% of 1,648,275,307 is roughly 80,000,000 actions. As such the whole process only takes %TODO: calc
of a second per row, making this very fit for real-time anomaly detection. The actual testing (without training) stage here takes even shorter, generally taking a single second per user for all their actions, which would make a network that only runs tests and doesn't continue learning as a user's behavior changes, would be even more feasible.