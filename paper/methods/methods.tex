\chapter{Methods}\label{ch:methods}

In a dataset as big as the one that is being used, there is a lot of information that is very essential but not included by default in a row (such as whether the user connected to an unvisited computer), while there is also some data that is completely useless by default (text data that the network can't handle as a vector). This is the reason for the data being turned into so-called features. These features are then sent to the network to learn after being split into a training and test set. 
Because users behave very differently in the dataset (and every big network), the decision was made to train one network per user. The possibility of using one network for all users was explored, but this introduced some problems like the amount of actions for all users not being the same, the network moving to recognize the median values, and simple performance reasons. After training on the training set, the network then runs on the test set. A list is then composed containing the differences between the expected and actual values. Any items in this list that deviate too much from the median are then labeled as anomalies.

%cSpell:words akent
\section{Data}
The dataset from \cite{akent-2015-enterprise-data} contains a number of different types of data, as described in the introduction. For this thesis we will only be using the authentication data as that is by far the largest dataset at 1,648,275,307 events. The dataset has a total of 12,425 users over 17,684 computers and spans 58 consecutive days. The data was entirely anonymized in addition to the timeframe at which it was captured not being disclosed. The data format can be seen in table~\ref{tab:data}

\begin{table}[]
	\centering
	\caption{The dataset structure}
	\label{tab:data}
	\resizebox{\linewidth}{!}{
		\begin{tabular}{lllllllll}
			time & source user@domain & destination user@domain & source computer & destination computer & authentication type & logon type & authentication orientation & success/failure \\ \hline
			1    & C625@DOM1          & U147@DOM1               & C625            & C625                 & Negotiate           & Batch      & LogOn                      & Success         \\
			1    & C625@DOM1          & SYSTEM@C653             & C653            & C653                 & Negotiate           & Service    & LogOn                      & Success         \\
			1    & C625@DOM1          & SYSTEM@C653             & C660            & C660                 & Negotiate           & Service    & LogOn                      & Success        
		\end{tabular}
	}
\end{table}

\begin{table}[]
	\centering
	\caption{My caption}
	\label{tab:features}
	\resizebox{\linewidth}{!}{
		\begin{tabular}{lll}
			Index & Feature                & Description                                                                \\ \hline
			0     & domains delta          & 1 if a previously unvisited domain was accessed, 0 otherwise               \\
			1     & dest users delta       & 1 if a previously unvisited destination user was accessed, 0 otherwise     \\
			2     & src computers delta    & 1 if a previously unvisited source computer was accessed, 0 otherwise      \\
			3     & dest computers delta   & 1 if a previously unvisited destination computer was accessed, 0 otherwise \\
			4     & src computer           & The current source computer                                                \\
			5     & dest computer          & The current destination computer                                           \\
			6     & time since last access & The time (in seconds) since the last time any network activity occurred    \\
			7     & auth type              & What type of authentication type was used (one of enum)                    \\
			8     & logon type             & What type of logon type was used (one of enum)                             \\
			9     & auth orientation       & What type of authentication orientation was used (one of enum)             \\
			10    & success or failure     & 1 if the login succeeded, 0 if it didn't                                  
		\end{tabular}
	}
\end{table}

\section{Features}
Because the raw data has some unneeded values, some that need to be transformed, and some that need to be added, features are made from the original rows. Because increasing the amount of features has a big performance impact, keeping the amount of features low, while still making sure the most important features are extracted is very important. The features are taken from the actions of one user over the whole dataset. For the features see table~\ref{tab:features}.

The features have been chosen to fill the values that the network will probably be using. For example the network is unlikely to keep track of a list of every computer the user logged in to, but would probably be interested in knowing whether the user logged in to a new computer. Additionally the network is unlikely to subtract the previous action's timestamp from the current timestamp, but will probably be interested in knowing the time since the last action to see whether the user is doing lots of operations at once, is doing actions at a normal human speed, or if they're barely doing anything.

Unfortunately there is no knowing whether better features could be chosen as the dataset is unlabeled and there is no way of knowing whether the detected anomalies are actually anomalies or whether we missed some apart from labeling it. As such that would be a good candidate for further research.

\section{Preprocessing}
In order to have both a training and test set for every user, the data is split up. 70\% is used for training and 30\% is used for the test set. This is done separately for every user, making sure that each user has the same 70-30 split. The network expects only real-valued numbers from the range [0,1], however because the features contain integer values, these values have to be scaled down to fit into the range. This is done by taking the maximum value for every column and dividing every value in that column by that maximum,linearly scaling every value down to the range [0,1]. This operation is performed for the training and test set at the same time before they are split up, ensuring that the scaling factor is the same for both sets. The data is kept in chronological order as it was read originally, ensuring that the input data closely resembles real input data and making maximum use of the LSTM's ability to make sense of sequences.

\section{Running}
After preprocessing, the data is then fed into the network (s). For performance reasons, a single network is created, which is then used as the base for every other network. Instead of creating a new network for every user, new weights are created that are then applied to the base network. This network consist of 3 layers, with the first two being stateful LSTMs, and the third layer being a dense layer. The network uses a batch size of 32. This number was chosen because increasing this value would decrease the weight of individual actions when in the testing stage as the network always only accepts input of that size and outputs a single \enquote{loss} value. Increasing the batch size would reduce the significance of a single anomaly on the loss value. Reducing the batch size however, quickly slows down the network by a lot. The network is trained first on the supplied training data, always trying to optimize for the lowest loss value using the mean squared error function. This is repeated for 25 epochs. This value was chosen because increasing this value would introduce overfitting and reducing it would result in higher loss values overall. Note that these values are not perfect, seeing as there was no way to objectively compare the results of different epoch or batch size values. 

After training, the test set is then fed into the network. Because of the limitation allowing only groups of the size of the $batch\_size$ to be tested, groups are constructed for every action that include $1 - batch\_size$ actions of the previous actions. This ensures that every possible construction of $batch\_size$ consecutive actions is tested. Not doing this would introduce scenarios where two consecutive anomalous actions would be split off into two separate groups, reducing the anomaly score given by the network in both instances.

The losses from each of these groups are then collected, after which the interquartile range (IQR) is calculated. The IQR attempts to find statistical outliers based on the median values of a distribution. This is done by calculating a distribution's median, which is then called the IQR, then calculating the median of both the upper and lower half, called Q1 and Q3 respectively. Any values that lay outside of the ranges of the following functions, where $x$ is the value, are then called outliers.

$$ x < Q1 - 1.5 IQR $$

$$ x > Q3 + 1.5 IQR $$

In practice however, the first form of outlier will almost never be found, as that would mean an action so perfectly fits the user, it is an anomaly, which is very unlikely to point to actual anomalous behavior.

%cSpell:words chollet
All the code was written in Python, using the~\cite{chollet2015keras} Keras deep learning library. The default LSTM was used.