\chapter{Methods}\label{ch:methods}

In a dataset as big as the one that is being used, there is a lot of information that is very essential but not included by default in a row (such as whether the user connected to an unvisited computer), while there is also some data that is completely useless by default (text data that the network can't handle as a vector). This is the reason for the data being turned into so-called features. These features are then sent to the network to learn after being split into a training and test set. 
Because users behave very differently in the dataset (and every big network), the decision was made to train one network per user. The possibility of using one network for all users was explored, but this introduced some problems like the amount of actions for all users not being the same, the network moving to recognize the median values, and simple performance reasons. After training on the training set, the network then runs on the test set. A list is then composed containing the differences between the expected and actual values. Any items in this list that deviate too much from the median are then labeled as anomalies.

%cSpell:words akent
\section{Data}
The dataset from~\cite{akent-2015-enterprise-data} contains a number of different types of data, as described in the introduction. For this thesis we will only be using the authentication data as that is by far the largest dataset at 1,648,275,307 events. The dataset has a total of 12,425 users over 17,684 computers and spans 58 consecutive days. The data was entirely anonymized in addition to the timeframe at which it was captured not being disclosed. The data format can be seen in table~\ref{tab:data}

\begin{table}[]
	\centering
	\caption{The dataset structure}\label{tab:data}
	\resizebox{\linewidth}{!}{
		\begin{tabular}{lllllllll}
			time & source user@domain & destination user@domain & source computer & destination computer & authentication type & logon type & authentication orientation & success/failure \\ \hline
			1    & C625@DOM1          & U147@DOM1               & C625            & C625                 & Negotiate           & Batch      & LogOn                      & Success         \\
			1    & C625@DOM1          & SYSTEM@C653             & C653            & C653                 & Negotiate           & Service    & LogOn                      & Success         \\
			1    & C625@DOM1          & SYSTEM@C653             & C660            & C660                 & Negotiate           & Service    & LogOn                      & Success        
		\end{tabular}
	}
\end{table}

\begin{table}[]
	\centering
	\caption{The features}\label{tab:features}
	\resizebox{\linewidth}{!}{
		\begin{tabular}{lll}
			Index & Feature                & Description                                                                \\ \hline
			0     & domains delta          & 1 if a previously unvisited domain was accessed, 0 otherwise               \\
			1     & dest users delta       & 1 if a previously unvisited destination user was accessed, 0 otherwise     \\
			2     & src computers delta    & 1 if a previously unvisited source computer was accessed, 0 otherwise      \\
			3     & dest computers delta   & 1 if a previously unvisited destination computer was accessed, 0 otherwise \\
			4     & src computer           & The current source computer                                                \\
			5     & dest computer          & The current destination computer                                           \\
			6     & time since last access & The time (in seconds) since the last time any network activity occurred    \\
			7     & auth type              & What type of authentication type was used (one of enum)                    \\
			8     & logon type             & What type of logon type was used (one of enum)                             \\
			9     & auth orientation       & What type of authentication orientation was used (one of enum)             \\
			10    & success or failure     & 1 if the login succeeded, 0 if it didn't                                  
		\end{tabular}
	}
\end{table}

\section{Features}
Because the raw data has some unneeded values, some that need to be transformed, and some that need to be added, features are made from the original rows. Because increasing the amount of features has a big performance impact, keeping the amount of features low, while still making sure the most important features are extracted is very important. The features are taken from the actions of one user over the whole dataset. For the features see table~\ref{tab:features}.

The features have been chosen to fill the values that the network will probably be using. For example the network is unlikely to keep track of a list of every computer the user logged in to, but would probably be interested in knowing whether the user logged in to a new computer. Additionally the network is unlikely to subtract the previous action's timestamp from the current timestamp, but will probably be interested in knowing the time since the last action to see whether the user is doing lots of operations at once, is doing actions at a normal human speed, or if they're barely doing anything.

\section{Preprocessing}
In order to have both a training and test set for every user, the data is split up. 70\% is used for training and 30\% is used for the test set. This is done separately for every user, making sure that each user has the same 70--30 split. The network expects only real-valued numbers from the range [0,1], however because the features contain integer values, these values have to be normalized to fit into the range. This is done by taking the maximum value for every column and dividing every value in that column by that maximum, linearly scaling every value down to the range [0,1]. This is done by applying the formula below to every row, where $x$ is the old row and $x'$ is the new row:

$$ x' = x / \max(x) $$

This operation is performed for the training and test set at the same time before they are split up, ensuring that the scaling factor is the same for both sets. The data is kept in chronological order as it was read originally, ensuring that the input data closely resembles real input data and making maximum use of the LSTM's ability to make sense of sequences.

Keep in mind that in a real-time scenario, scaling can not be done by using the same factor for both the training and test set as the eventual $max$ value is unknown, leading to values that fall above the [0,1] range. This can however be solved by taking the maximum possible or reasonable value as a scaling factor for both test sets (for example no user will ever access more computers than are available on the network and no user will have more seconds between their last action than are in a human lifetime).

%cSpell:words srivastava
\section{Training}
After preprocessing, the training data is then used as input for the networks (s). For performance reasons, a single network is created, which is then used as the base for every other network. Instead of creating a new network for every user, new weights are created that are then applied to the base network. This network consist of 3 layers, with the first two being stateful LSTMs, and the third layer being a dense layer. The network uses a batch size of 32. This number was chosen because increasing this value would decrease the weight of individual actions when in the testing stage as the network always only accepts input of that size and outputs a single \enquote{loss} value. Increasing the batch size would reduce the significance of a single anomaly on the loss value. Reducing the batch size however, quickly slows down the network by a lot. The network is trained first on the supplied training data, always trying to optimize for the lowest loss value using the mean squared error function, which measures the average of the squares of the deviations, giving an approximation of the deviation from the expected value. This is repeated for 25 epochs. This value was chosen because increasing this value would introduce overfitting and reducing it would result in higher loss values overall. As another measure to prevent overfitting, a dropout factor of 0.5, and a recurrent dropout factor of 0.2 is used for both LSTM layers. A dropout factor, which randomly drops certain input vectors, and a recurrent dropout factor that randomly drops out vectors between states, were shown to prevent overfitting in~\cite{srivastava2014dropout}. Note that these values are not perfect, seeing as there was no way to objectively compare the results of different parameters.

\section{Testing}
After training, the network is applied to the test set. Because of the limitation allowing only groups of the size of the $batch\_size$ to be tested, groups are constructed for every action that include $1 - batch\_size$ actions of the previous actions. This ensures that every possible construction of $batch\_size$ consecutive actions is tested. Not doing this would introduce scenarios where two consecutive anomalous actions would be split off into two separate groups, reducing the loss amount given by the network in both instances.

The losses from each of these groups are then collected, after which the interquartile range (IQR) is calculated. The IQR function attempts to find statistical outliers based on the median values of a distribution. This is done by calculating the medians of both the upper and lower half of a distribution, who are then called Q1 and Q3 respectively. The IQR is then equal to $Q3 - Q1$. Any values that lay outside of the ranges of the following functions, where $x$ is the input value, are then called outliers.

$$ x < Q1 - 1.5 IQR $$
$$ x > Q3 + 1.5 IQR $$

In practice however, the first form of outlier will almost never be found, as that would mean an action so perfectly fits the user, it is an anomaly, which is very unlikely to point to actual anomalous behavior.

%cSpell:words chollet
All the code was written in Python, using the~\cite{chollet2015keras} Keras deep learning library. The standard Keras LSTM layer was used.