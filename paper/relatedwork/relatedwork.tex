\chapter{Related Work}\label{ch:related_work}

%cSpell:words roesch portnoy intrusiondetection
The field of intrusion detection has always been a very active field, becoming even more active as the need for better systems increases. In~\cite{roesch1999snort}, a lightweight way to scan a network's active data flow and to find possible intrusions based on known attacks was proposed, while in~\cite{lee1998data}, simple classifiers were used to find anomalous behavior based on known intrusion techniques and changes in behavior based solely on the users' learned behavior. More advanced techniques like clustering have also been used to find anomalies in unlabeled data sets. Later  there were attempts to build a system that also detected yet unknown intrusion techniques and anomalous changes in user behavior using clustering, attempting to go beyond the constant lookout for new intrusion techniques that felt like a cat-and-mouse game for network administrators, as explored by~\cite{Portnoy01intrusiondetection}.

%cSpell:words cannady
With the upcoming field of artificial neural networks and deep learning, the interest for using artificial neural networks for anomaly detection and intrusion detection has also increased greatly as they show great potential. Applying a simple backpropagation neural network to the terminal commands a user executed, in \cite{ryan1998intrusion}, an attempt was made to identify users by these commands, reaching a 96\% accuracy in finding unusual activity. Neural networks perform a lot better on noisy data where some fields may be missing or incomplete, as \cite{cannady1998artificial} shows, applying a neural network to noisy computer network metadata in order to detect different methods of attack.

%cSpell:words malhotra olsson akent
Recurrent neural networks (RNNs) using Long Short Term Memory (LSTM) proved very useful in finding so-called time series anomalies, which are anomalies over a time frame with multiple actions in it instead of single-action anomalies. LSTMs excel at this are due to their ability to remember past input, as is shown in ~\cite{malhotra2015long}, where a stacked LSTM, trained to recognize regular behavior, was demonstrated performing well on 4 different datasets. LSTMs tend to be able to find so-called collective anomalies where other types of anomaly detection would not find them, being able to link together multiple instances of slightly off behavior into a definitive anomaly. This technique was applied in \cite{olsson2015probabilistic}, where they were able to probabilistically group together the contribution of individual anomalies in order to find significantly anomalous groups of cases.